{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Unet is an fully convolutional architrecture that specializes in Image Segmentation and semantic segmentation. It does not contain any dense or fully connected layers. It help mask objects and also helps in segmenting the objects. It was initially developed for medical image segmentation using sigle class model but it can also be used for multi class segmentation. U net architecture is a U shape architecture and consists of two parts encoders and decoders. The encoder part is a mixture of CNN and Maxpooling layers with Relu activation at the end of each stage. With every evel we descend the size of the input halves and channels double. This encoder part explain well about the What of the Image but in segmentation we also need to know the masks and where in the image they are located. In decoder part we need to reach back to the same image size we started with. hence instead of Max pooling we will use transpose convolutions or deconvolutions. It will upsample the image. In the original paper the output was smaller than the input because they used un padded convolutions to reduce or oversample the image. In decoder channel size reduces with each level. \n\nThere are skip connections between contraction and expansion paths. Skip connection provide us a very valuable idea upon where things are in the image. \n\nWatch this video on Youtube for the simple explanation : https://www.youtube.com/watch?v=-dfSZ_uLfo8\n\nRecommended paper walkthrough : https://www.youtube.com/watch?v=oLvmLJkmXuc\n\nFor a basic idea : https://www.youtube.com/watch?v=azM57JuQpQI","metadata":{}},{"cell_type":"code","source":"# Making necessary imports \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport numpy as np\nimport pandas as pd\nimport scipy.io\nfrom skimage.transform import resize\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport gc\ngc.collect()\nimport os","metadata":{"execution":{"iopub.status.busy":"2022-08-06T12:07:37.490945Z","iopub.execute_input":"2022-08-06T12:07:37.491355Z","iopub.status.idle":"2022-08-06T12:07:37.881188Z","shell.execute_reply.started":"2022-08-06T12:07:37.491324Z","shell.execute_reply":"2022-08-06T12:07:37.880140Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"input_path = os.path.join('..', 'input', 'chiu-2015', '2015_BOE_Chiu')\nsubject_path = [os.path.join(input_path, 'Subject_0{}.mat'.format(i)) for i in range(1, 10)] + [os.path.join(input_path, 'Subject_10.mat')]\n\ndata_indexes = [10, 15, 20, 25, 28, 30, 32, 35, 40, 45, 50]\n\nwidth = 768\nheight = 496","metadata":{"execution":{"iopub.status.busy":"2022-08-06T12:07:38.663672Z","iopub.execute_input":"2022-08-06T12:07:38.664788Z","iopub.status.idle":"2022-08-06T12:07:38.670319Z","shell.execute_reply.started":"2022-08-06T12:07:38.664741Z","shell.execute_reply":"2022-08-06T12:07:38.669628Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"subject_path","metadata":{"execution":{"iopub.status.busy":"2022-08-06T12:07:39.618920Z","iopub.execute_input":"2022-08-06T12:07:39.619590Z","iopub.status.idle":"2022-08-06T12:07:39.626185Z","shell.execute_reply.started":"2022-08-06T12:07:39.619536Z","shell.execute_reply":"2022-08-06T12:07:39.624909Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"mat = scipy.io.loadmat(subject_path[0])\nimg_tensor = mat['images']\nmanual_fluid_tensor_1 = mat['manualFluid1']\n\nimg_array = np.transpose(img_tensor, (2, 0, 1))\nmanual_fluid_array = np.transpose(manual_fluid_tensor_1, (2, 0, 1))","metadata":{"execution":{"iopub.status.busy":"2022-08-06T12:07:40.603217Z","iopub.execute_input":"2022-08-06T12:07:40.604518Z","iopub.status.idle":"2022-08-06T12:07:42.645311Z","shell.execute_reply.started":"2022-08-06T12:07:40.604475Z","shell.execute_reply":"2022-08-06T12:07:42.644057Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"mat['images'].shape","metadata":{"execution":{"iopub.status.busy":"2022-08-06T12:07:42.648308Z","iopub.execute_input":"2022-08-06T12:07:42.649136Z","iopub.status.idle":"2022-08-06T12:07:42.656540Z","shell.execute_reply.started":"2022-08-06T12:07:42.649091Z","shell.execute_reply":"2022-08-06T12:07:42.655420Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"img_array.shape","metadata":{"execution":{"iopub.status.busy":"2022-08-06T12:07:42.657723Z","iopub.execute_input":"2022-08-06T12:07:42.658615Z","iopub.status.idle":"2022-08-06T12:07:42.667918Z","shell.execute_reply.started":"2022-08-06T12:07:42.658558Z","shell.execute_reply":"2022-08-06T12:07:42.667016Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"# There are 61 images in category 1 \nlen(img_array)","metadata":{"execution":{"iopub.status.busy":"2022-08-06T12:07:43.832607Z","iopub.execute_input":"2022-08-06T12:07:43.833540Z","iopub.status.idle":"2022-08-06T12:07:43.840807Z","shell.execute_reply.started":"2022-08-06T12:07:43.833486Z","shell.execute_reply":"2022-08-06T12:07:43.839702Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"plt.imshow(img_array[20])","metadata":{"execution":{"iopub.status.busy":"2022-08-06T12:07:46.736688Z","iopub.execute_input":"2022-08-06T12:07:46.737543Z","iopub.status.idle":"2022-08-06T12:07:47.054719Z","shell.execute_reply.started":"2022-08-06T12:07:46.737500Z","shell.execute_reply":"2022-08-06T12:07:47.053328Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"plt.imshow(manual_fluid_array[20])","metadata":{"execution":{"iopub.status.busy":"2022-08-06T12:07:47.592728Z","iopub.execute_input":"2022-08-06T12:07:47.593725Z","iopub.status.idle":"2022-08-06T12:07:47.844771Z","shell.execute_reply.started":"2022-08-06T12:07:47.593687Z","shell.execute_reply":"2022-08-06T12:07:47.843649Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"def thresh(x):\n    if x == 0:\n        return 0\n    else:\n        return 1\n\nthresh = np.vectorize(thresh, otypes=[np.float])\n\ndef create_dataset(paths):\n    x = []\n    y = []\n    \n    for path in paths:\n        mat = scipy.io.loadmat(path)\n        img_tensor = mat['images']\n        fluid_tensor = mat['manualFluid1']\n        \n        img_array = np.transpose(img_tensor, (2, 0 ,1)) / 255\n        fluid_array = np.transpose(fluid_tensor, (2, 0 ,1))\n        fluid_array = thresh(fluid_array)\n        \n        for idx in data_indexes:\n            x += [np.expand_dims(img_array[idx], 2)]\n            y += [np.expand_dims(fluid_array[idx], 2)]\n        \n    return np.array(x), np.array(y)\n\nx_train, y_train = create_dataset(subject_path[:9])\nx_val, y_val = create_dataset(subject_path[9:])","metadata":{"execution":{"iopub.status.busy":"2022-08-06T12:17:05.373491Z","iopub.execute_input":"2022-08-06T12:17:05.375709Z","iopub.status.idle":"2022-08-06T12:18:53.937180Z","shell.execute_reply.started":"2022-08-06T12:17:05.375639Z","shell.execute_reply":"2022-08-06T12:18:53.935650Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"x_train.shape, y_train.shape, x_val.shape, y_val.shape","metadata":{"execution":{"iopub.status.busy":"2022-08-06T12:19:21.182270Z","iopub.execute_input":"2022-08-06T12:19:21.182905Z","iopub.status.idle":"2022-08-06T12:19:21.196428Z","shell.execute_reply.started":"2022-08-06T12:19:21.182854Z","shell.execute_reply":"2022-08-06T12:19:21.194748Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"plt.imshow(x_train[15,:,:,0])","metadata":{"execution":{"iopub.status.busy":"2022-08-06T12:19:46.596973Z","iopub.execute_input":"2022-08-06T12:19:46.597418Z","iopub.status.idle":"2022-08-06T12:19:46.949432Z","shell.execute_reply.started":"2022-08-06T12:19:46.597384Z","shell.execute_reply":"2022-08-06T12:19:46.947721Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"plt.imshow(y_train[15,:,:,0])","metadata":{"execution":{"iopub.status.busy":"2022-08-06T12:19:58.788998Z","iopub.execute_input":"2022-08-06T12:19:58.789458Z","iopub.status.idle":"2022-08-06T12:19:59.093024Z","shell.execute_reply.started":"2022-08-06T12:19:58.789422Z","shell.execute_reply":"2022-08-06T12:19:59.091181Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"markdown","source":"The Unet Architecture : fchollet notebook : https://keras.io/examples/vision/oxford_pets_image_segmentation/","metadata":{}},{"cell_type":"code","source":"# keras\nfrom keras.models import Model, load_model\nfrom keras.layers import Input\nfrom keras.layers.core import Dropout, Lambda\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras import backend as K\nimport tensorflow as tf\n\ninputs = Input((height, width,1))\n\nc1_1 = Conv2D(8, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(inputs)\nc1_2 = Conv2D(8, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c1_1)\np1 = MaxPooling2D((2, 2))(c1_2)\n\nc2_1 = Conv2D(12, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(p1)\nc2_2 = Conv2D(12, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c2_1)\np2 = MaxPooling2D((2, 2))(c2_2)\n\nc3_1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(p2)\nc3_2 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c3_1)\np3 = MaxPooling2D((2, 2))(c3_2)\n\nc4_1 = Conv2D(24, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(p3)\nc4_2 = Conv2D(24, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c4_1)\np4 = MaxPooling2D((2, 2))(c4_2)\n\nc5_1 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(p4)\nc5_2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c5_1)\n\nc6_t = Conv2DTranspose(24, (2, 2), strides=(2, 2), padding='same') (c5_2)\nc6_c = concatenate([c6_t, c4_2])\nc6_1 = Conv2D(24, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c6_c)\nc6_2 = Conv2D(24, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c6_1)\n\nc7_t = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c6_2)\nc7_c = concatenate([c7_t, c3_2])\nc7_1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c7_c)\nc7_2 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c7_1)\n\nc8_t = Conv2DTranspose(12, (2, 2), strides=(2, 2), padding='same') (c7_2)\nc8_c = concatenate([c8_t, c2_2])\nc8_1 = Conv2D(12, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c8_c)\nc8_2 = Conv2D(12, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c8_1)\n\nc9_t = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8_2)\nc9_c = concatenate([c9_t, c1_2])\nc9_1 = Conv2D(8, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c9_c)\nc9_2 = Conv2D(8, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c9_1)\n\noutputs = Conv2D(1, (1, 1), activation='sigmoid') (c9_2)\n\nmodel = Model(inputs=[inputs], outputs=[outputs])\nmodel.compile(optimizer='adam', loss='binary_crossentropy')\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-08-06T12:20:02.412882Z","iopub.execute_input":"2022-08-06T12:20:02.414189Z","iopub.status.idle":"2022-08-06T12:20:02.802335Z","shell.execute_reply.started":"2022-08-06T12:20:02.414110Z","shell.execute_reply":"2022-08-06T12:20:02.800862Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"results = model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=11, epochs=10)","metadata":{"execution":{"iopub.status.busy":"2022-08-06T12:20:10.107293Z","iopub.execute_input":"2022-08-06T12:20:10.107829Z","iopub.status.idle":"2022-08-06T12:24:09.115025Z","shell.execute_reply.started":"2022-08-06T12:20:10.107792Z","shell.execute_reply":"2022-08-06T12:24:09.113704Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"pred = model.predict(x_val)","metadata":{"execution":{"iopub.status.busy":"2022-08-06T12:24:09.118169Z","iopub.execute_input":"2022-08-06T12:24:09.118625Z","iopub.status.idle":"2022-08-06T12:24:10.297422Z","shell.execute_reply.started":"2022-08-06T12:24:09.118566Z","shell.execute_reply":"2022-08-06T12:24:10.296220Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"pred = (pred > 0.5).astype(np.uint8)","metadata":{"execution":{"iopub.status.busy":"2022-08-06T12:24:10.301740Z","iopub.execute_input":"2022-08-06T12:24:10.303365Z","iopub.status.idle":"2022-08-06T12:24:10.314009Z","shell.execute_reply.started":"2022-08-06T12:24:10.303291Z","shell.execute_reply":"2022-08-06T12:24:10.312384Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"# prediction visualization\nnrows = 6\nfig, axes = plt.subplots(nrows=nrows, ncols=3, figsize=(15, 10))\nfor i in range(nrows):\n    axes[i][0].imshow(np.reshape(x_val[2*i], (496, 768)), cmap='Greys_r')\n    axes[i][1].imshow(np.reshape(y_val[2*i], (496, 768)), cmap='Greys_r')\n    axes[i][2].imshow(np.reshape(pred[2*i], (496, 768)), cmap='Greys_r')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-06T12:24:10.316986Z","iopub.execute_input":"2022-08-06T12:24:10.317946Z","iopub.status.idle":"2022-08-06T12:24:12.892539Z","shell.execute_reply.started":"2022-08-06T12:24:10.317895Z","shell.execute_reply":"2022-08-06T12:24:12.890816Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}