{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Basic imports of tensorflow and keras \nimport numpy as np\nimport os\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sn; sn.set(font_scale=1.4)\nfrom sklearn.utils import shuffle           \nimport matplotlib.pyplot as plt             \nimport cv2                                 \nimport tensorflow as tf                \nfrom tqdm import tqdm\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-28T07:11:05.781624Z","iopub.execute_input":"2022-05-28T07:11:05.782199Z","iopub.status.idle":"2022-05-28T07:11:05.791273Z","shell.execute_reply.started":"2022-05-28T07:11:05.782154Z","shell.execute_reply":"2022-05-28T07:11:05.790397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Step 1 : Preparation of Data. As we know that we cannot pass the image data directly into the model without converting it into a readable array. We have image data with six classes and we need to put each image with a label. There are two ways in which we can prepare this data : \n\n1. One way is that we can read the data using the opencv and then use it. \n2. Another way is using keras.preprocessing and directly accessing teh image_dataset_from_directory feature \n\nBefore starting with these steps its important to check whether all the images are right or not. We should not feed corrupt images to our model for training. ","metadata":{}},{"cell_type":"code","source":"# Checking whether the images are corrupt or not. In this exercise we do not need this as the data is very clean \n# But in some cases we may encounter a situtaion in which data is not that clean and hence we need to ensure that\n# we need to check the image data for whether its corrupt or not and delete the data. \n\n# We may not repeat this exercise in testing as it will help us to determine how the model performs if there are \n# some corrupt images feeded to the model \n\nimport os\n\nnum_skipped = 0\nfor folder_name in (\"buildings\", \"forest\",\"glacier\",\"mountain\",\"sea\",\"street\"):\n    folder_path = os.path.join(\"../input/intel-image-classification/seg_train/seg_train\", folder_name)\n    for fname in os.listdir(folder_path):\n        fpath = os.path.join(folder_path, fname)\n        try:\n            fobj = open(fpath, \"rb\")\n            is_jfif = tf.compat.as_bytes(\"JFIF\") in fobj.peek(10)\n        finally:\n            fobj.close()\n\n        if not is_jfif:\n            num_skipped += 1\n            # Delete corrupted image\n            os.remove(fpath)\n\nprint(\"Deleted %d images\" % num_skipped)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T07:11:05.797409Z","iopub.execute_input":"2022-05-28T07:11:05.797661Z","iopub.status.idle":"2022-05-28T07:12:25.012019Z","shell.execute_reply.started":"2022-05-28T07:11:05.797629Z","shell.execute_reply":"2022-05-28T07:12:25.011232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reading the data through open CV and using lables against it and then putting the entire thing in tensors \n# (image,labels)\n\nclass_names = ['mountain', 'street', 'glacier', 'buildings', 'sea', 'forest']\nclass_names_label = {class_name:i for i, class_name in enumerate(class_names)}\n\nnb_classes = len(class_names)\n\nIMAGE_SIZE = (150, 150)\n\nprint(class_names_label)\n\ndef load_data():\n    \"\"\"\n        Load the data:\n            - 14,034 images to train the network.\n            - 3,000 images to evaluate how accurately the network learned to classify images.\n    \"\"\"\n    \n    datasets = ['../input/intel-image-classification/seg_train/seg_train', '../input/intel-image-classification/seg_test/seg_test']\n    output = []\n    \n    # Iterate through training and test sets\n    for dataset in datasets:\n        \n        images = []\n        labels = []\n        \n        print(\"Loading {}\".format(dataset))\n        \n        # Iterate through each folder corresponding to a category\n        for folder in os.listdir(dataset):\n            label = class_names_label[folder]\n            \n            # Iterate through each image in our folder\n            # Progress bar appears due to tqdm \n            for file in tqdm(os.listdir(os.path.join(dataset, folder))):\n                \n                # Get the path name of the image\n                img_path = os.path.join(os.path.join(dataset, folder), file)\n                # Open and resize the img\n                image = cv2.imread(img_path)\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                image = cv2.resize(image, IMAGE_SIZE) \n                \n                # Append the image and its corresponding label to the output\n                images.append(image)\n                labels.append(label)\n                \n        images = np.array(images, dtype = 'float32')\n        labels = np.array(labels, dtype = 'int32')   \n        \n        output.append((images, labels))\n\n    return output\n\n(train_images, train_labels), (test_images, test_labels) = load_data()\n\nn_train = train_labels.shape[0]\nn_test = test_labels.shape[0]\n\nprint (\"Number of training examples: {}\".format(n_train))\nprint (\"Number of testing examples: {}\".format(n_test))\nprint (\"Each image is of size: {}\".format(IMAGE_SIZE))","metadata":{"execution":{"iopub.status.busy":"2022-05-28T07:12:25.013988Z","iopub.execute_input":"2022-05-28T07:12:25.014298Z","iopub.status.idle":"2022-05-28T07:13:03.706811Z","shell.execute_reply.started":"2022-05-28T07:12:25.014256Z","shell.execute_reply":"2022-05-28T07:13:03.706061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This method works best when you just have classified images but no train test split, One more way in which we can read the images as per fchollet notebook is this \n# as illustrated below. This works best when you have validation and train datasets togather and you need to make a test-train split. In this case we do not need validation\n# split and hence we can keep the validation split as none\n\n# Visit the documentation at https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory\n\n# This is an easy way of doing the same thing when dealing with an image classification problem. \n\nimage_size = (150,150)\nbatch_size = 32 \ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\"../input/intel-image-classification/seg_train/seg_train\",\n                                                               labels='inferred',\n                                                                label_mode='int',\n                                                                class_names=None,\n                                                                color_mode='rgb',\n                                                                batch_size=batch_size,\n                                                                image_size=image_size,\n                                                                shuffle=True,\n                                                                seed=None,\n                                                                validation_split=None,\n                                                                subset=None,\n                                                                interpolation='bilinear',\n                                                                follow_links=False,\n                                                                crop_to_aspect_ratio=False\n                                                              )\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(\"../input/intel-image-classification/seg_test/seg_test\",\n                                                            labels='inferred',\n                                                                label_mode='int',\n                                                                class_names=None,\n                                                                color_mode='rgb',\n                                                                batch_size=batch_size,\n                                                                image_size=image_size,\n                                                                shuffle=True,\n                                                                seed=None,\n                                                                validation_split=None,\n                                                                subset=None,\n                                                                interpolation='bilinear',\n                                                                follow_links=False,\n                                                                crop_to_aspect_ratio=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T07:13:03.708254Z","iopub.execute_input":"2022-05-28T07:13:03.708727Z","iopub.status.idle":"2022-05-28T07:13:09.712150Z","shell.execute_reply.started":"2022-05-28T07:13:03.708686Z","shell.execute_reply":"2022-05-28T07:13:09.711388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After we have put the data in train and test splits and in a ready move tensors. We need to rescale our images. As we know that an image may have pixels ranging from 0-255 which makes it very difficult for our model to train as there are 255 different varieties, it has to deal with. Its very important to scale the images between 0-1 and hence we divide the pixel array of image with 255. ","metadata":{}},{"cell_type":"code","source":"# In case of normal reading we can perform like this \ntrain_images = train_images / 255.0 \ntest_images = test_images / 255.0","metadata":{"execution":{"iopub.status.busy":"2022-05-28T07:13:09.714088Z","iopub.execute_input":"2022-05-28T07:13:09.715165Z","iopub.status.idle":"2022-05-28T07:13:11.708717Z","shell.execute_reply.started":"2022-05-28T07:13:09.715122Z","shell.execute_reply":"2022-05-28T07:13:11.707717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lets visualize the images now and the tensors that has been converted using labels and array. ","metadata":{}},{"cell_type":"code","source":"for images, labels in train_ds.take(1):\n    print(images,labels)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T07:13:11.714279Z","iopub.execute_input":"2022-05-28T07:13:11.716499Z","iopub.status.idle":"2022-05-28T07:13:12.385219Z","shell.execute_reply.started":"2022-05-28T07:13:11.716456Z","shell.execute_reply":"2022-05-28T07:13:12.384525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now lets visualise our dataset after labelling. I have shown three ways of visualisation just to make you feel the difference between the various ways to visualise the image. \n\n1. simple image array with numpy \n2. simple image array \n3. image array with numpy and uint8","metadata":{}},{"cell_type":"code","source":"# Visualising the data \nimport matplotlib.pyplot as plt\nimport numpy\n\nplt.figure(figsize = (10,10))\nfor images, labels in train_ds.take(1):\n    for i in range(9):\n        ax = plt.subplot(3,3,i+1)\n        plt.imshow(images[i].numpy())\n        plt.title(int(labels[i]))\n        plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-05-28T07:13:12.389180Z","iopub.execute_input":"2022-05-28T07:13:12.392166Z","iopub.status.idle":"2022-05-28T07:13:13.375623Z","shell.execute_reply.started":"2022-05-28T07:13:12.392123Z","shell.execute_reply":"2022-05-28T07:13:13.374902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualising the data \nimport matplotlib.pyplot as plt\nimport numpy\n\nplt.figure(figsize = (10,10))\nfor images, labels in train_ds.take(1):\n    for i in range(9):\n        ax = plt.subplot(3,3,i+1)\n        plt.imshow(images[i])\n        plt.title(int(labels[i]))\n        plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-05-28T07:13:13.376822Z","iopub.execute_input":"2022-05-28T07:13:13.377112Z","iopub.status.idle":"2022-05-28T07:13:14.211580Z","shell.execute_reply.started":"2022-05-28T07:13:13.377075Z","shell.execute_reply":"2022-05-28T07:13:14.210784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualising the data \nimport matplotlib.pyplot as plt\nimport numpy\n\nplt.figure(figsize = (10,10))\nfor images, labels in train_ds.take(1):\n    for i in range(9):\n        ax = plt.subplot(3,3,i+1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        print(images[i].shape)\n        plt.title(int(labels[i]))\n        plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-05-28T07:13:14.212958Z","iopub.execute_input":"2022-05-28T07:13:14.213362Z","iopub.status.idle":"2022-05-28T07:13:15.306525Z","shell.execute_reply.started":"2022-05-28T07:13:14.213324Z","shell.execute_reply":"2022-05-28T07:13:15.305914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now activities such as resizing, normalisation of pixels in 0-1 and also creating augmented data, in case data for training is less can be done using data augmentor or data augmentation techniques as well. In this case below i have made data augmentation a part of model training process where I have added sequential layers in Keras. This will augment the images while training itself. ","metadata":{}},{"cell_type":"code","source":"# Rescaling the RGB channel of [0-255] between [0-1] as [0-255] is nit suited for the neural network \n# We will create a data augmentation pre-processor for this purpose which can be used in augmenting the data as well \n# as with operations like rescaling and others \n\ndata_augmentation = keras.Sequential([\n    layers.RandomFlip(\"horizontal\"),\n    layers.RandomRotation(0.4)\n])","metadata":{"execution":{"iopub.status.busy":"2022-05-28T07:13:15.307687Z","iopub.execute_input":"2022-05-28T07:13:15.308034Z","iopub.status.idle":"2022-05-28T07:13:15.340268Z","shell.execute_reply.started":"2022-05-28T07:13:15.307988Z","shell.execute_reply":"2022-05-28T07:13:15.339642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets visualise the augmented samples \nplt.figure(figsize = (10,10))\nfor images, _ in train_ds.take(1):\n    for i in range(9):\n        augmented_images = data_augmentation(images)\n        ax = plt.subplot(3,3,i+1)\n        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n        plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-05-28T07:13:15.343393Z","iopub.execute_input":"2022-05-28T07:13:15.343931Z","iopub.status.idle":"2022-05-28T07:13:16.404429Z","shell.execute_reply.started":"2022-05-28T07:13:15.343901Z","shell.execute_reply":"2022-05-28T07:13:16.400439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Standardize the Data, Simultaneous augmetation and resizing of the images is a good phenomenon if you are training \n# your model on GPU. It will perform this operation simulteneously with the model training \n# Data Augmentation is inactive during test time and hence the samples will only be augmented during fit()\n# not during evaluate() or predict()\n\ninput_shape = (150,150,3)\ninputs = keras.Input(shape = input_shape)\nx = data_augmentation(inputs)\nx = layers.Rescaling(1./255)(x)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T07:13:16.405642Z","iopub.execute_input":"2022-05-28T07:13:16.406413Z","iopub.status.idle":"2022-05-28T07:13:16.554460Z","shell.execute_reply.started":"2022-05-28T07:13:16.406372Z","shell.execute_reply":"2022-05-28T07:13:16.553763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# When you are training on CPU. This will happen asynchronously and will be buffered before going to the model\n#augmented_train_ds = train_ds.map(lambda x,y : (data_augmentation(x,training = True),y))","metadata":{"execution":{"iopub.status.busy":"2022-05-28T07:13:16.555776Z","iopub.execute_input":"2022-05-28T07:13:16.556056Z","iopub.status.idle":"2022-05-28T07:13:16.561607Z","shell.execute_reply.started":"2022-05-28T07:13:16.556020Z","shell.execute_reply":"2022-05-28T07:13:16.559459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Configuring the Dataset for performance \n# buffered prefetching of the data so that we can yield data from disk \n# without I/O becoming blocking \n\ntrain_ds = train_ds.prefetch(buffer_size = 32)\nval_ds = val_ds.prefetch(buffer_size = 32)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T07:13:16.563198Z","iopub.execute_input":"2022-05-28T07:13:16.563520Z","iopub.status.idle":"2022-05-28T07:13:16.569795Z","shell.execute_reply.started":"2022-05-28T07:13:16.563481Z","shell.execute_reply":"2022-05-28T07:13:16.569056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we are ready to prepare a model with basics of neural netork. Lets start with a very basic model where we have two convolutional layers, 2 max pooling, two batch normalisation, one flatten and one dense. We can make this model as complicated as we want using the basic concepts on Artificial neural networks and CNN. ","metadata":{}},{"cell_type":"code","source":"\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (150, 150, 3)), \n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(6, activation=tf.nn.softmax)\n])","metadata":{"execution":{"iopub.status.busy":"2022-05-28T07:13:16.571405Z","iopub.execute_input":"2022-05-28T07:13:16.571696Z","iopub.status.idle":"2022-05-28T07:13:16.650815Z","shell.execute_reply.started":"2022-05-28T07:13:16.571656Z","shell.execute_reply":"2022-05-28T07:13:16.650182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-05-28T07:13:16.652037Z","iopub.execute_input":"2022-05-28T07:13:16.652267Z","iopub.status.idle":"2022-05-28T07:13:16.664648Z","shell.execute_reply.started":"2022-05-28T07:13:16.652235Z","shell.execute_reply":"2022-05-28T07:13:16.663880Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-28T07:13:16.665622Z","iopub.execute_input":"2022-05-28T07:13:16.665868Z","iopub.status.idle":"2022-05-28T07:13:16.678401Z","shell.execute_reply.started":"2022-05-28T07:13:16.665833Z","shell.execute_reply":"2022-05-28T07:13:16.677736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_images, train_labels, batch_size=128, epochs=5, validation_split = 0.2)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T07:13:16.679429Z","iopub.execute_input":"2022-05-28T07:13:16.679724Z","iopub.status.idle":"2022-05-28T07:14:03.408638Z","shell.execute_reply.started":"2022-05-28T07:13:16.679689Z","shell.execute_reply":"2022-05-28T07:14:03.407575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can fit the same model using train_ds and test_ds datasets as well. ","metadata":{}},{"cell_type":"code","source":"epochs = 5\n\ncallbacks = [\n    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\"),\n]\nmodel.compile(\n    optimizer=keras.optimizers.Adam(1e-3),\n    loss=\"binary_crossentropy\",\n    metrics=[\"accuracy\"],\n)\nmodel.fit(\n    train_ds, epochs=epochs, callbacks=callbacks, validation_data=val_ds,\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-28T07:14:03.410136Z","iopub.execute_input":"2022-05-28T07:14:03.410884Z","iopub.status.idle":"2022-05-28T07:15:37.247720Z","shell.execute_reply.started":"2022-05-28T07:14:03.410836Z","shell.execute_reply":"2022-05-28T07:15:37.246881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Predictions using the above models and metrics to observe in the above model. The prediction for all six classes came to be same and hence it is difficult to predict which class. Hence we should delve in some more complicated architectures and see how our model trains there. One can definitely increased epochs to increase the efficiency. ","metadata":{}},{"cell_type":"code","source":"img = keras.preprocessing.image.load_img(\n    \"../input/intel-image-classification/seg_pred/seg_pred/10004.jpg\", target_size=IMAGE_SIZE\n)\nimg_array = keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0)  # Create batch axis\n\npredictions = model.predict(img_array)\nscore = predictions[0]\nprint(score)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T07:15:37.248904Z","iopub.execute_input":"2022-05-28T07:15:37.249173Z","iopub.status.idle":"2022-05-28T07:15:37.418688Z","shell.execute_reply.started":"2022-05-28T07:15:37.249137Z","shell.execute_reply":"2022-05-28T07:15:37.416725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now lets use Keras tuner to tune the hyperparameter in our model. KerasTuner is an easy-to-use, scalable hyperparameter optimization framework that solves the pain points of hyperparameter search.One can follow the link : https://keras.io/keras_tuner/ for understanding of Keras Tuner. Hyper Parameter tuning can be of several types : \n\n1. Randomised Search CV : It is faster than the grid search CV. Grid Saerch works well when we have a small number of hyperparameters and each hyper parameter has the same impact on the validation score of the model. Randomised search is batter when the magnitude of influence are inbalanced, which is more likely to happen as your number of parameter is growing. Randomised search will be randomly picking up some areas. It will provide borader ideas on Hyperparameter. It will narrow down our results and then one can apply Grid Search over this. \n\n2. Grid Search CV :  It goes and check every possible combination fo parameters and every parameter list we provide. It may not necessarily be in one order. This can be cumbersome.  \n\n3. Byesian Optimisation : It builds a probability function for the objective function and use it to select most promising hyperparameter to evaluate true objective function. It in contrast to grid search keeps a track of past evaluation results which they use to form a probablistic model mapping. Read this amazing article on Towards Data Science : https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f\n\n\nIn keras.tuner we can simply employ these methods for hyper parameter optimisation. \n","metadata":{}},{"cell_type":"code","source":"# Installing Keras Tuner \n!pip install keras-tuner","metadata":{"execution":{"iopub.status.busy":"2022-05-28T07:15:37.419986Z","iopub.execute_input":"2022-05-28T07:15:37.420325Z","iopub.status.idle":"2022-05-28T07:15:48.675641Z","shell.execute_reply.started":"2022-05-28T07:15:37.420287Z","shell.execute_reply":"2022-05-28T07:15:48.674783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets define our model with some choices now so that we can tune the model using keras tuner and find the required hyper parameter \n# We have incorporated activation function as a Hyperparameter and dense units as Hyper parameter.\nimport keras_tuner as kt\ndef build_model_keras_tuner(hp):\n    \n    model = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(hp.Choice(\"units\",[32,16,8]), (3, 3), activation = hp.Choice(\"activation\", [\"relu\", \"tanh\"]), input_shape = (150, 150, 3)), \n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(32, (3, 3), activation = hp.Choice(\"activation\", [\"relu\", \"tanh\"])),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(hp.Choice(\"units\",[128,64,32,16,8]), activation=tf.nn.relu),\n    tf.keras.layers.Dense(6, activation=tf.nn.softmax)\n    ])\n    \n    #Do not forget to copile the model \n    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n                loss=keras.losses.SparseCategoricalCrossentropy(),\n                metrics=['accuracy'])\n    \n    return model ","metadata":{"execution":{"iopub.status.busy":"2022-05-28T07:15:48.677433Z","iopub.execute_input":"2022-05-28T07:15:48.677696Z","iopub.status.idle":"2022-05-28T07:15:48.815297Z","shell.execute_reply.started":"2022-05-28T07:15:48.677659Z","shell.execute_reply":"2022-05-28T07:15:48.814549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking whether the model builds or not \nbuild_model_keras_tuner(kt.HyperParameters())","metadata":{"execution":{"iopub.status.busy":"2022-05-28T07:15:48.816887Z","iopub.execute_input":"2022-05-28T07:15:48.817153Z","iopub.status.idle":"2022-05-28T07:15:48.892281Z","shell.execute_reply.started":"2022-05-28T07:15:48.817117Z","shell.execute_reply":"2022-05-28T07:15:48.891572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Applying Random Search for tuning the hyperparameters \ntuner = kt.RandomSearch(\n    hypermodel=build_model_keras_tuner,\n    objective=\"val_accuracy\",\n    max_trials=3,\n    executions_per_trial=2,\n    overwrite=True,\n    directory=\"my_dir\",\n    project_name=\"helloworld\",\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T07:15:48.893681Z","iopub.execute_input":"2022-05-28T07:15:48.893941Z","iopub.status.idle":"2022-05-28T07:15:48.963419Z","shell.execute_reply.started":"2022-05-28T07:15:48.893905Z","shell.execute_reply":"2022-05-28T07:15:48.962804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuner.search_space_summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-28T07:15:48.964585Z","iopub.execute_input":"2022-05-28T07:15:48.964922Z","iopub.status.idle":"2022-05-28T07:15:48.970837Z","shell.execute_reply.started":"2022-05-28T07:15:48.964883Z","shell.execute_reply":"2022-05-28T07:15:48.970181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuner.search(train_ds, epochs=3,validation_data=val_ds)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T07:15:48.971941Z","iopub.execute_input":"2022-05-28T07:15:48.972404Z","iopub.status.idle":"2022-05-28T07:20:56.748788Z","shell.execute_reply.started":"2022-05-28T07:15:48.972365Z","shell.execute_reply":"2022-05-28T07:20:56.747976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the top 2 models.\nmodels = tuner.get_best_models(num_models=2)\nbest_model = models[0]\n","metadata":{"execution":{"iopub.status.busy":"2022-05-28T07:20:56.750274Z","iopub.execute_input":"2022-05-28T07:20:56.750538Z","iopub.status.idle":"2022-05-28T07:20:57.383769Z","shell.execute_reply.started":"2022-05-28T07:20:56.750501Z","shell.execute_reply":"2022-05-28T07:20:57.383051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-28T07:20:57.385133Z","iopub.execute_input":"2022-05-28T07:20:57.385370Z","iopub.status.idle":"2022-05-28T07:20:57.398219Z","shell.execute_reply.started":"2022-05-28T07:20:57.385338Z","shell.execute_reply":"2022-05-28T07:20:57.397427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lets implement a more complicated model over this data and look at how this work. This has been picked up from fchollet notebook. https://keras.io/examples/vision/image_classification_from_scratch/","metadata":{}},{"cell_type":"markdown","source":"Go checkout separable Conv2D here : https://towardsdatascience.com/a-basic-introduction-to-separable-convolutions-b99ec3102728","metadata":{}},{"cell_type":"code","source":"def make_model(input_shape, num_classes):\n    inputs = keras.Input(shape=input_shape)\n    # Image augmentation block\n    x = data_augmentation(inputs)\n\n    # Entry block\n    x = layers.Rescaling(1.0 / 255)(x)\n    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation(\"relu\")(x)\n\n    x = layers.Conv2D(64, 3, padding=\"same\")(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation(\"relu\")(x)\n\n    previous_block_activation = x  # Set aside residual\n\n    for size in [128, 256, 512, 728]:\n        x = layers.Activation(\"relu\")(x)\n        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.Activation(\"relu\")(x)\n        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n\n        # Project residual\n        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n            previous_block_activation\n        )\n        x = layers.add([x, residual])  # Add back residual\n        previous_block_activation = x  # Set aside next residual\n\n    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation(\"relu\")(x)\n\n    x = layers.GlobalAveragePooling2D()(x)\n    if num_classes == 2:\n        activation = \"sigmoid\"\n        units = 1\n    else:\n        activation = \"softmax\"\n        units = num_classes\n\n    x = layers.Dropout(0.5)(x)\n    outputs = layers.Dense(units, activation=activation)(x)\n    return keras.Model(inputs, outputs)\n\n\nmodel = make_model(input_shape=image_size + (3,), num_classes=2)\nkeras.utils.plot_model(model, show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T07:21:04.153053Z","iopub.execute_input":"2022-05-28T07:21:04.153312Z","iopub.status.idle":"2022-05-28T07:21:06.007845Z","shell.execute_reply.started":"2022-05-28T07:21:04.153284Z","shell.execute_reply":"2022-05-28T07:21:06.006909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use sparse categorical entropy because binary and categorical crossentropy is more useful in case of when we \n# have one hot encoding\n\nepochs = 5\n\ncallbacks = [\n    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\"),\n]\nmodel.compile(\n    optimizer=keras.optimizers.Adam(1e-3),\n    loss=\"sparse_categorical_crossentropy\",\n    metrics=[\"accuracy\"],\n)\nmodel.fit(\n    train_ds, epochs=epochs, callbacks=callbacks, validation_data=val_ds,\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T07:22:20.729894Z","iopub.execute_input":"2022-05-28T07:22:20.730292Z","iopub.status.idle":"2022-05-28T07:28:51.424601Z","shell.execute_reply.started":"2022-05-28T07:22:20.730248Z","shell.execute_reply":"2022-05-28T07:28:51.423885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#cancelled the run owing to many images\n\nimport pandas as pd\npre_directory_path = \"../input/intel-image-classification/seg_pred/seg_pred\"\ndf = pd.DataFrame(columns = [\"Image_Name\",\"Class\",\"Score\"])\n\nfor image in os.listdir(pre_directory_path):\n    img = keras.preprocessing.image.load_img(\n    os.path.join(pre_directory_path,image), target_size=image_size)\n    img_array = keras.preprocessing.image.img_to_array(img)\n    img_array = tf.expand_dims(img_array, 0)\n    predictions = model.predict(img_array)\n    score = predictions[0]\n    pred_dict = {\"Image_Name\": image, \"Class\": np.argmax(score),\"Score\":np.max(score) }\n    df = df.append(pred_dict, ignore_index = True)\n    break\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-28T07:46:27.240491Z","iopub.execute_input":"2022-05-28T07:46:27.240872Z","iopub.status.idle":"2022-05-28T07:46:27.314979Z","shell.execute_reply.started":"2022-05-28T07:46:27.240820Z","shell.execute_reply":"2022-05-28T07:46:27.314208Z"},"trusted":true},"execution_count":null,"outputs":[]}]}